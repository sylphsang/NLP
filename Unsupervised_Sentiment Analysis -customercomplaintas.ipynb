{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (3150, 5)\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"amazon_alexa.tsv\",sep='\\t')\n",
    "file.head()\n",
    "print('shape',file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cleaned = file.dropna().drop_duplicates().reset_index(drop=True).rename(columns={'verified_reviews':'title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating       date         variation  \\\n",
      "0       5  31-Jul-18  Charcoal Fabric    \n",
      "1       5  31-Jul-18  Charcoal Fabric    \n",
      "2       4  31-Jul-18    Walnut Finish    \n",
      "3       5  31-Jul-18  Charcoal Fabric    \n",
      "4       5  31-Jul-18  Charcoal Fabric    \n",
      "\n",
      "                                               title  feedback  \n",
      "0                                      Love my Echo!         1  \n",
      "1                                          Loved it!         1  \n",
      "2  Sometimes while playing a game, you can answer...         1  \n",
      "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
      "4                                              Music         1  \n",
      "shape (2435, 5)\n"
     ]
    }
   ],
   "source": [
    "print(file_cleaned.head())\n",
    "print('shape',file_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:05:46: NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    0.721150\n",
       "4    0.141684\n",
       "1    0.057906\n",
       "3    0.046407\n",
       "2    0.032854\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_cleaned.rating.value_counts()/len(file_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>title</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rating, date, variation, title, feedback]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_cleaned[file_cleaned.rating==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cleaned = file_cleaned[file_cleaned.rating!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text, remove_polish_letters):\n",
    "    ''' Pre process and convert texts to a list of words \n",
    "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
    "    text = remove_polish_letters(text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cleaned.title = file_cleaned.title.apply(lambda x: text_to_word_list(x, unidecode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = file_cleaned.copy()\n",
    "file_model = file_model[file_model.title.str.len()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>title</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>[love, my, echo, !]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>[loved, it, !]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>[sometimes, while, playing, a, game, you, can,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>[i, have, had, a, lot, of, fun, with, this, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Heather Gray Fabric</td>\n",
       "      <td>[i, received, the, echo, as, a, gift, i, neede...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date             variation  \\\n",
       "0       5  31-Jul-18      Charcoal Fabric    \n",
       "1       5  31-Jul-18      Charcoal Fabric    \n",
       "2       4  31-Jul-18        Walnut Finish    \n",
       "3       5  31-Jul-18      Charcoal Fabric    \n",
       "5       5  31-Jul-18  Heather Gray Fabric    \n",
       "\n",
       "                                               title  feedback  \n",
       "0                                [love, my, echo, !]         1  \n",
       "1                                     [loved, it, !]         1  \n",
       "2  [sometimes, while, playing, a, game, you, can,...         1  \n",
       "3  [i, have, had, a, lot, of, fun, with, this, th...         1  \n",
       "5  [i, received, the, echo, as, a, gift, i, neede...         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:22:24: collecting all words and their counts\n",
      "INFO - 12:22:24: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 12:22:24: collected 31976 word types from a corpus of 66936 words (unigram + bigrams) and 2337 sentences\n",
      "INFO - 12:22:24: using 31976 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 12:22:24: source_vocab length 31976\n",
      "INFO - 12:22:24: Phraser built with 1562 phrasegrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loved', 'it', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in file_model.title]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[1]\n",
    "sent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loved', 'it', '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:22:36: collecting all words and their counts\n",
      "INFO - 12:22:36: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 12:22:36: collected 5389 word types from a corpus of 58484 raw words and 2337 sentences\n",
      "INFO - 12:22:36: Loading a fresh vocabulary\n",
      "INFO - 12:22:36: effective_min_count=3 retains 2100 unique words (38% of original 5389, drops 3289)\n",
      "INFO - 12:22:36: effective_min_count=3 leaves 54026 word corpus (92% of original 58484, drops 4458)\n",
      "INFO - 12:22:36: deleting the raw counts dictionary of 5389 items\n",
      "INFO - 12:22:36: sample=1e-05 downsamples 2100 most-common words\n",
      "INFO - 12:22:36: downsampling leaves estimated 6516 word corpus (12.1% of prior 54026)\n",
      "INFO - 12:22:36: estimated required memory for 2100 words and 300 dimensions: 6090000 bytes\n",
      "INFO - 12:22:36: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:23:43: training model with 3 workers on 2100 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4\n",
      "INFO - 12:23:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:43: EPOCH - 1 : training on 58484 raw words (6438 effective words) took 0.2s, 31174 effective words/s\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:44: EPOCH - 2 : training on 58484 raw words (6573 effective words) took 0.3s, 23583 effective words/s\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:44: EPOCH - 3 : training on 58484 raw words (6476 effective words) took 0.3s, 23382 effective words/s\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:44: EPOCH - 4 : training on 58484 raw words (6567 effective words) took 0.3s, 23708 effective words/s\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:45: EPOCH - 5 : training on 58484 raw words (6465 effective words) took 0.2s, 27269 effective words/s\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:45: EPOCH - 6 : training on 58484 raw words (6499 effective words) took 0.2s, 26229 effective words/s\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:45: EPOCH - 7 : training on 58484 raw words (6502 effective words) took 0.2s, 26620 effective words/s\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:45: EPOCH - 8 : training on 58484 raw words (6394 effective words) took 0.3s, 24007 effective words/s\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:46: EPOCH - 9 : training on 58484 raw words (6547 effective words) took 0.2s, 28345 effective words/s\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:46: EPOCH - 10 : training on 58484 raw words (6543 effective words) took 0.2s, 28850 effective words/s\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:46: EPOCH - 11 : training on 58484 raw words (6341 effective words) took 0.2s, 27885 effective words/s\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:46: EPOCH - 12 : training on 58484 raw words (6587 effective words) took 0.2s, 29309 effective words/s\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:47: EPOCH - 13 : training on 58484 raw words (6587 effective words) took 0.2s, 28087 effective words/s\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:47: EPOCH - 14 : training on 58484 raw words (6427 effective words) took 0.2s, 28322 effective words/s\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:47: EPOCH - 15 : training on 58484 raw words (6434 effective words) took 0.2s, 31046 effective words/s\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:47: EPOCH - 16 : training on 58484 raw words (6555 effective words) took 0.2s, 28900 effective words/s\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:47: EPOCH - 17 : training on 58484 raw words (6456 effective words) took 0.2s, 29341 effective words/s\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:48: EPOCH - 18 : training on 58484 raw words (6555 effective words) took 0.2s, 28664 effective words/s\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:48: EPOCH - 19 : training on 58484 raw words (6593 effective words) took 0.2s, 30495 effective words/s\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:48: EPOCH - 20 : training on 58484 raw words (6611 effective words) took 0.3s, 24737 effective words/s\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:48: EPOCH - 21 : training on 58484 raw words (6466 effective words) took 0.3s, 25823 effective words/s\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:49: EPOCH - 22 : training on 58484 raw words (6571 effective words) took 0.2s, 28848 effective words/s\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:49: EPOCH - 23 : training on 58484 raw words (6535 effective words) took 0.2s, 26847 effective words/s\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:23:49: EPOCH - 24 : training on 58484 raw words (6540 effective words) took 0.2s, 27129 effective words/s\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:49: EPOCH - 25 : training on 58484 raw words (6524 effective words) took 0.3s, 25094 effective words/s\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:50: EPOCH - 26 : training on 58484 raw words (6491 effective words) took 0.2s, 27893 effective words/s\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:50: EPOCH - 27 : training on 58484 raw words (6532 effective words) took 0.3s, 25474 effective words/s\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:50: EPOCH - 28 : training on 58484 raw words (6481 effective words) took 0.2s, 29345 effective words/s\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:50: EPOCH - 29 : training on 58484 raw words (6540 effective words) took 0.2s, 28261 effective words/s\n",
      "INFO - 12:23:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 12:23:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 12:23:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 12:23:51: EPOCH - 30 : training on 58484 raw words (6538 effective words) took 0.2s, 31614 effective words/s\n",
      "INFO - 12:23:51: training on a 1754520 raw words (195368 effective words) took 7.7s, 25471 effective words/s\n",
      "INFO - 12:23:51: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.13 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:26:14: saving Word2Vec object under word2vec_amazon.model, separately None\n",
      "INFO - 12:26:14: not storing attribute vectors_norm\n",
      "INFO - 12:26:14: not storing attribute cum_table\n",
      "INFO - 12:26:14: saved word2vec_amazon.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec_amazon.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export = file_model.copy()\n",
    "file_export['old_title'] = file_export.title\n",
    "file_export.old_title = file_export.old_title.str.join(' ')\n",
    "file_export.title = file_export.title.apply(lambda x: ' '.join(bigram[x]))\n",
    "file_export.rating = file_export.rating.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          love my echo !\n",
       "1                                              loved it !\n",
       "2       sometimes while playing a game you can answer ...\n",
       "3       i have had a lot of fun with this thing my 4 y...\n",
       "5       i received the echo as a gift i needed another...\n",
       "                              ...                        \n",
       "2429    listening to music searching locations checkin...\n",
       "2430    i do love these things i have them running my ...\n",
       "2431    only complaint i have is that the sound qualit...\n",
       "2433                           nice little unit no issues\n",
       "2434    the echo dot was easy to set up and use it hel...\n",
       "Name: old_title, Length: 2337, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_export['old_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_export[['title', 'rating']].to_csv('cleaned_dataset_amazon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:39:57: loading Word2Vec object from ../preprocessing_and_embeddings/word2vec_amazon.model\n",
      "INFO - 12:39:57: loading wv recursively from ../preprocessing_and_embeddings/word2vec_amazon.model.wv.* with mmap=None\n",
      "INFO - 12:39:57: setting ignored attribute vectors_norm to None\n",
      "INFO - 12:39:57: loading vocabulary recursively from ../preprocessing_and_embeddings/word2vec_amazon.model.vocabulary.* with mmap=None\n",
      "INFO - 12:39:57: loading trainables recursively from ../preprocessing_and_embeddings/word2vec_amazon.model.trainables.* with mmap=None\n",
      "INFO - 12:39:57: setting ignored attribute cum_table to None\n",
      "INFO - 12:39:57: loaded ../preprocessing_and_embeddings/word2vec_amazon.model\n"
     ]
    }
   ],
   "source": [
    "word_vectors = Word2Vec.load(\"../preprocessing_and_embeddings/word2vec_amazon.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:40:22: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('support', 0.9999841451644897),\n",
       " ('cleaning', 0.999981164932251),\n",
       " ('functionality', 0.9999806880950928),\n",
       " ('light', 0.9999804496765137),\n",
       " ('issues', 0.9999803900718689),\n",
       " ('supposed_to', 0.9999799728393555),\n",
       " ('z_wave', 0.9999797344207764),\n",
       " ('alexa_app', 0.9999796748161316),\n",
       " ('miss', 0.9999791383743286),\n",
       " ('my_favorite', 0.9999787211418152)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_cluster_center = model.cluster_centers_[0]\n",
    "negative_cluster_center = model.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>[-0.026340038, 0.07963559, -0.031905122, 0.008...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>[-0.027167274, 0.08063432, -0.03152201, 0.0081...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>echo</td>\n",
       "      <td>[-0.0275069, 0.08009132, -0.031630386, 0.00876...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>[-0.02724483, 0.080774404, -0.031526707, 0.008...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved</td>\n",
       "      <td>[-0.026332214, 0.080499455, -0.031330157, 0.00...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>tv_shows</td>\n",
       "      <td>[-0.02728316, 0.08089661, -0.031357393, 0.0087...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>inexpensive</td>\n",
       "      <td>[-0.02732649, 0.0801433, -0.030886805, 0.00870...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>regular_tv</td>\n",
       "      <td>[-0.02627897, 0.079481065, -0.0322978, 0.00856...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>buffering</td>\n",
       "      <td>[-0.025984358, 0.08114232, -0.032166343, 0.007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>of_space</td>\n",
       "      <td>[-0.026446596, 0.07996994, -0.031728666, 0.008...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                            vectors  cluster\n",
       "0            love  [-0.026340038, 0.07963559, -0.031905122, 0.008...        1\n",
       "1              my  [-0.027167274, 0.08063432, -0.03152201, 0.0081...        1\n",
       "2            echo  [-0.0275069, 0.08009132, -0.031630386, 0.00876...        1\n",
       "3               !  [-0.02724483, 0.080774404, -0.031526707, 0.008...        0\n",
       "4           loved  [-0.026332214, 0.080499455, -0.031330157, 0.00...        1\n",
       "...           ...                                                ...      ...\n",
       "2095     tv_shows  [-0.02728316, 0.08089661, -0.031357393, 0.0087...        0\n",
       "2096  inexpensive  [-0.02732649, 0.0801433, -0.030886805, 0.00870...        0\n",
       "2097   regular_tv  [-0.02627897, 0.079481065, -0.0322978, 0.00856...        1\n",
       "2098    buffering  [-0.025984358, 0.08114232, -0.032166343, 0.007...        1\n",
       "2099     of_space  [-0.026446596, 0.07996994, -0.031728666, 0.008...        1\n",
       "\n",
       "[2100 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.iloc[2].vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0077113 , 0.00766221]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform([words.iloc[0].vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>[-0.026340038, 0.07963559, -0.031905122, 0.008...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>130.510623</td>\n",
       "      <td>-130.510623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>[-0.027167274, 0.08063432, -0.03152201, 0.0081...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>129.987863</td>\n",
       "      <td>-129.987863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>echo</td>\n",
       "      <td>[-0.0275069, 0.08009132, -0.031630386, 0.00876...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>131.840632</td>\n",
       "      <td>-131.840632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>[-0.02724483, 0.080774404, -0.031526707, 0.008...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>129.175936</td>\n",
       "      <td>129.175936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved</td>\n",
       "      <td>[-0.026332214, 0.080499455, -0.031330157, 0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>129.854841</td>\n",
       "      <td>-129.854841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>[-0.027279275, 0.07926728, -0.031287294, 0.008...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.546892</td>\n",
       "      <td>127.546892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sometimes</td>\n",
       "      <td>[-0.027463114, 0.080234565, -0.03178065, 0.008...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>133.607922</td>\n",
       "      <td>133.607922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>while_playing</td>\n",
       "      <td>[-0.027587425, 0.07945566, -0.03169518, 0.0081...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.188644</td>\n",
       "      <td>112.188644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>[-0.027170578, 0.08081399, -0.031429715, 0.007...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137.553236</td>\n",
       "      <td>137.553236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you_can</td>\n",
       "      <td>[-0.027126111, 0.08069215, -0.030887974, 0.007...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>135.410788</td>\n",
       "      <td>-135.410788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words                                            vectors  cluster  \\\n",
       "0           love  [-0.026340038, 0.07963559, -0.031905122, 0.008...        1   \n",
       "1             my  [-0.027167274, 0.08063432, -0.03152201, 0.0081...        1   \n",
       "2           echo  [-0.0275069, 0.08009132, -0.031630386, 0.00876...        1   \n",
       "3              !  [-0.02724483, 0.080774404, -0.031526707, 0.008...        0   \n",
       "4          loved  [-0.026332214, 0.080499455, -0.031330157, 0.00...        1   \n",
       "5             it  [-0.027279275, 0.07926728, -0.031287294, 0.008...        0   \n",
       "6      sometimes  [-0.027463114, 0.080234565, -0.03178065, 0.008...        0   \n",
       "7  while_playing  [-0.027587425, 0.07945566, -0.03169518, 0.0081...        0   \n",
       "8              a  [-0.027170578, 0.08081399, -0.031429715, 0.007...        0   \n",
       "9        you_can  [-0.027126111, 0.08069215, -0.030887974, 0.007...        1   \n",
       "\n",
       "   cluster_value  closeness_score  sentiment_coeff  \n",
       "0             -1       130.510623      -130.510623  \n",
       "1             -1       129.987863      -129.987863  \n",
       "2             -1       131.840632      -131.840632  \n",
       "3              1       129.175936       129.175936  \n",
       "4             -1       129.854841      -129.854841  \n",
       "5              1       127.546892       127.546892  \n",
       "6              1       133.607922       133.607922  \n",
       "7              1       112.188644       112.188644  \n",
       "8              1       137.553236       137.553236  \n",
       "9             -1       135.410788      -135.410788  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('cleaned_dataset_amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = final_file.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       4\n",
       "3       5\n",
       "4       5\n",
       "       ..\n",
       "2332    5\n",
       "2333    5\n",
       "2334    5\n",
       "2335    5\n",
       "2336    5\n",
       "Name: rating, Length: 2337, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_weighting.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\320083146\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.title)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.title.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.title.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.title, file_weighting.rating]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-130.51062274205154, -129.9878628551397, -131...</td>\n",
       "      <td>[2.330562684574323, 2.4149297233108626, 3.3725...</td>\n",
       "      <td>love my echo !</td>\n",
       "      <td>0</td>\n",
       "      <td>-758.058879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-129.8548408762586, 127.54689240323215, 129.1...</td>\n",
       "      <td>[5.230690617415853, 1.659502291417221, 2.35845...</td>\n",
       "      <td>loved it !</td>\n",
       "      <td>0</td>\n",
       "      <td>-162.910349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[133.60792231119075, 112.18864393473083, 137.5...</td>\n",
       "      <td>[5.38975531204554, 7.3707567809121235, 2.42199...</td>\n",
       "      <td>sometimes while_playing a game you_can answer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6983.826723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-129.95542160860472, 123.77409090397802, 132....</td>\n",
       "      <td>[3.5953052597960764, 2.707317686800056, 3.8592...</td>\n",
       "      <td>i have had a_lot of fun with this_thing my 4 y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1151.176776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-129.95542160860472, -128.21009717746549, 116...</td>\n",
       "      <td>[3.5953052597960764, 5.923837797975797, 1.7431...</td>\n",
       "      <td>i received the echo as a_gift i needed another...</td>\n",
       "      <td>0</td>\n",
       "      <td>1406.115325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>[-138.9777684256068, -133.5282246028226, 99.95...</td>\n",
       "      <td>[5.355853760369858, 3.259882916738812, 6.67760...</td>\n",
       "      <td>listening_to music searching locations checkin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1164.165536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>[-129.95542160860472, 137.0524957050663, -130....</td>\n",
       "      <td>[7.190610519592153, 7.748498438891286, 4.66112...</td>\n",
       "      <td>i do love these_things i have them running my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10300.795597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>[-122.24625312487345, -129.95542160860472, 123...</td>\n",
       "      <td>[6.677609600352178, 8.98826314949019, 10.82927...</td>\n",
       "      <td>only_complaint i have is that the sound_qualit...</td>\n",
       "      <td>0</td>\n",
       "      <td>5284.852601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>[-126.68754077843764, 140.11219733080557, 132....</td>\n",
       "      <td>[4.662706579809913, 5.42484663185681, 5.578997...</td>\n",
       "      <td>nice little unit no_issues</td>\n",
       "      <td>0</td>\n",
       "      <td>206.344459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>[116.8619603751175, 133.55198395769958, 130.96...</td>\n",
       "      <td>[1.7431356672214862, 4.235262564982973, 9.5775...</td>\n",
       "      <td>the echo_dot was easy to set_up and use it hel...</td>\n",
       "      <td>0</td>\n",
       "      <td>3626.498833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2337 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentiment_coeff  \\\n",
       "0     [-130.51062274205154, -129.9878628551397, -131...   \n",
       "1     [-129.8548408762586, 127.54689240323215, 129.1...   \n",
       "2     [133.60792231119075, 112.18864393473083, 137.5...   \n",
       "3     [-129.95542160860472, 123.77409090397802, 132....   \n",
       "4     [-129.95542160860472, -128.21009717746549, 116...   \n",
       "...                                                 ...   \n",
       "2332  [-138.9777684256068, -133.5282246028226, 99.95...   \n",
       "2333  [-129.95542160860472, 137.0524957050663, -130....   \n",
       "2334  [-122.24625312487345, -129.95542160860472, 123...   \n",
       "2335  [-126.68754077843764, 140.11219733080557, 132....   \n",
       "2336  [116.8619603751175, 133.55198395769958, 130.96...   \n",
       "\n",
       "                                           tfidf_scores  \\\n",
       "0     [2.330562684574323, 2.4149297233108626, 3.3725...   \n",
       "1     [5.230690617415853, 1.659502291417221, 2.35845...   \n",
       "2     [5.38975531204554, 7.3707567809121235, 2.42199...   \n",
       "3     [3.5953052597960764, 2.707317686800056, 3.8592...   \n",
       "4     [3.5953052597960764, 5.923837797975797, 1.7431...   \n",
       "...                                                 ...   \n",
       "2332  [5.355853760369858, 3.259882916738812, 6.67760...   \n",
       "2333  [7.190610519592153, 7.748498438891286, 4.66112...   \n",
       "2334  [6.677609600352178, 8.98826314949019, 10.82927...   \n",
       "2335  [4.662706579809913, 5.42484663185681, 5.578997...   \n",
       "2336  [1.7431356672214862, 4.235262564982973, 9.5775...   \n",
       "\n",
       "                                               sentence  sentiment  \\\n",
       "0                                        love my echo !          0   \n",
       "1                                            loved it !          0   \n",
       "2     sometimes while_playing a game you_can answer ...          0   \n",
       "3     i have had a_lot of fun with this_thing my 4 y...          0   \n",
       "4     i received the echo as a_gift i needed another...          0   \n",
       "...                                                 ...        ...   \n",
       "2332  listening_to music searching locations checkin...          0   \n",
       "2333  i do love these_things i have them running my ...          0   \n",
       "2334  only_complaint i have is that the sound_qualit...          0   \n",
       "2335                         nice little unit no_issues          0   \n",
       "2336  the echo_dot was easy to set_up and use it hel...          0   \n",
       "\n",
       "      sentiment_rate  prediction  \n",
       "0        -758.058879           0  \n",
       "1        -162.910349           0  \n",
       "2        6983.826723           1  \n",
       "3        1151.176776           1  \n",
       "4        1406.115325           1  \n",
       "...              ...         ...  \n",
       "2332     1164.165536           1  \n",
       "2333    10300.795597           1  \n",
       "2334     5284.852601           1  \n",
       "2335      206.344459           1  \n",
       "2336     3626.498833           1  \n",
       "\n",
       "[2337 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "replacement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  619  1589\n",
       "1   17   112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.312794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.065844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.868217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.122404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.312794\n",
       "precision  0.065844\n",
       "recall     0.868217\n",
       "f1         0.122404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = replacement_df.prediction\n",
    "y_test = replacement_df.sentiment\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
